-----------------------------------------------------------------------------------
import numpy as np
array = np.array([3, 2, 1, 2])
print("Original array: ", array)
print("Append (6,7,8): ",np.append(array, [6, 7, 8]))
print("Insert Specific (10,11) at third second position: ", np.insert(array, 2, [10, 11]))
print("Delete values (1,3): ", np.delete(array, [0, 2]))
print("Unique element: ", np.unique(array))
print("Sorted array: ", np.sort(array))
np.savetxt('array.txt', array)
load = np.loadtxt('array.txt')
print("Loaded from array.txt: ", load)
-----------------------------------------------------------------------------------
import numpy as np
arr1 = np.array([1, 2, 3, 4, 5])
arr2 = np.array([6, 7, 8, 9, 10])
result_add = arr1 + arr2
print("Sum of array: ", result_add)
result_multiply = arr1 * arr2
print("Product of array: ", result_multiply)
print("Mean of array: ", np.mean(result_add))
print("Max value: ", np.max(result_multiply))
-----------------------------------------------------------------------------------
import numpy as np
grades = np.array([85, 90, 78, 92, 88, 76, 95, 89, 84, 91])
print("Average grade: ", np.mean(grades))
filter_grade = grades[grades > 90]
print("Number of Students scoring above 90: ", len(filter_grade))
std_grade = np.std(grades)
print("Standard deviation of grades: ", np.round(std_grade, decimals=2))
-----------------------------------------------------------------------------------
import numpy as np
from scipy.linalg import svd
matrix_A = np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9]])
matrix_B = np.array([[9, 8, 7],[6, 5, 4],[3, 2, 1]])
matrix_sum = matrix_A + matrix_B
print("Sum of matrices: \n", matrix_sum)
matrix_product = matrix_A * matrix_B
print("Product of matrices: \n", matrix_product)
matrix_dot = np.dot(matrix_A, matrix_B)
print("Dot Product of matrices: \n", matrix_dot)
matrix_A_transpose = np.transpose(matrix_A)
print("Transpose of matrix A: \n", matrix_A_transpose)
determinant_B = np.linalg.det(matrix_B)
print("Determinant of matrix B: ", determinant_B)
eigenvalues_A, eigenvectors_A = np.linalg.eig(matrix_A)
print("Eigenvalues of matrix A: \n", eigenvalues_A)
print("Eigenvectors of matrix A: \n", eigenvectors_A)
U, s, VT = svd(matrix_A)
print("SVD of Martrix A: ")
print("U: ",U)
print("s: ",s)
print("VT: ",VT)
-----------------------------------------------------------------------------------
import pandas as pd
df = pd.read_csv("sales_data.csv")
print(df.head())
print("Number of rows: ", len(df))
print("Number of columns: ", len(df.columns))
print("Total Revenue: ", sum(df['Revenue']))
-----------------------------------------------------------------------------------
import pandas as pd
df = pd.read_csv("student_data.csv")
print(df.head(), "\n")
age = df[df['Age'] > 19]
print("Students who are 20 years old or older: \n", age)
print("\nAverage GPA of all students:",df['GPA'].mean().round(2))
data1 = df.sort_values(by='GPA', ascending= False)
print("\nTop 5 students with highest GPA: \n", data1.head(5))
data2 = df.groupby('Age')['GPA'].mean().reset_index()
print("\nAverage GPA by age group: \n", data2)
-----------------------------------------------------------------------------------
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
marks = np.array([10,18,34,37, 33, 38, 34, 24, 80, 45, 49, 27, 31, 35, 42])
fig, ax = plt.subplots(figsize =(4, 4))
ax.hist(marks, color = "darkcyan", ec="black", lw=1)
plt.title('Histogram: Exam Score')
plt.ylabel('No. of students')
plt.xlabel('Score')
plt.figure(figsize=(4, 4))
sns.boxplot(y=marks, color='darkcyan')
plt.title('Quartile Plot: Exam Score')
plt.ylabel('Score')
plt.show()
-----------------------------------------------------------------------------------
#Heat Map charts:
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
x_values = [1, 2, 3, 4, 5]
y_values = [10, 15, 13, 18, 20]
data_values = [10, 15, 13, 18, 20]
df = pd.DataFrame({'x': x_values, 'y': y_values, 'value': data_values})
heatmap_data = df.pivot_table(index='x', columns='y', values='value')
fig, ax = plt.subplots(figsize=(10, 6))
sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', cbar=True)
plt.title('Heatmap Example')
plt.show()
#Scatter Plot:
x_values = [1, 2, 3, 4, 5]
data_values = [10, 15, 13, 18, 20]
df = pd.DataFrame({'x': x_values, 'value': data_values})
plt.scatter(df['x'], df['value'], marker='o', color='blue', label='Data Points')
plt.xlabel('No. of students')
plt.ylabel('Values')
plt.title('Scatter Plot based on Heatmap Values')
plt.show()
-----------------------------------------------------------------------------------
#Density Chart:
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
data = np.random.randn(1000)
sns.kdeplot(data, fill=True, color='blue', label='Density Plot')
plt.xlabel('X-Axis Label')
plt.ylabel('Density')
plt.title('Density Plot Example')
plt.show()
#Bubble Diagram:
import matplotlib.pyplot as plt
x = [1, 2, 3, 4, 5]
y = [10, 15, 13, 18, 20]
sizes = [100, 200, 300, 150, 250]
plt.scatter(x, y, s=sizes, alpha=0.5)
plt.xlabel('X-Axis')
plt.ylabel('Y-Axis')
plt.title('Bubble Chart Example')
plt.show()
-----------------------------------------------------------------------------------
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report
data = pd.read_csv("iris.csv")
X = data.drop("species", axis=1)
y = data["species"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
knn_classifier = KNeighborsClassifier(n_neighbors=3)
knn_classifier.fit(X_train, y_train)
y_pred = knn_classifier.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
report = classification_report(y_test, y_pred, target_names=data["species"].unique())
print("Classification Report:\n", report)
-----------------------------------------------------------------------------------
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report
data = pd.read_csv('iris.csv')
X = data.drop('species', axis=1)
y = data['species']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
clf = GaussianNB()
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')
report = classification_report(y_test, y_pred, target_names=data['species'].unique())
print(report)
-----------------------------------------------------------------------------------
import numpy as np
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
X = np.array([2, 3, 4, 5, 6]).reshape(-1, 1)
Y = np.array([60, 75, 85, 90, 95])
model = LinearRegression()
model.fit(X, Y)
Y_pred = model.predict(X)
slope = model.coef_[0]
intercept = model.intercept_
plt.scatter(X, Y, label='Data')
plt.plot(X, Y_pred, color='red', label=f'Regression Line (y = {slope:.2f}x + {intercept:.2f})')
plt.xlabel('Study Hours')
plt.ylabel('Exam Score')
plt.legend()
plt.title('Linear Regression: Study Hours vs. Exam Score')
plt.show()
new_SH = int(input("Enter the number of hours: "))
pred_Sc = model.predict(np.array([[new_SH]]))
print(f'Predicted Exam Score for {new_SH} study hours: {pred_Sc[0]:.2f}')
-----------------------------------------------------------------------------------
import pandas as pd
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
data = pd.read_csv("house-price.csv")
X = data[['No_Rooms', 'Sq_Foot', 'Age']].values
Y = data['Price'].values
model = LinearRegression()
model.fit(X, Y)
Y_pred = model.predict(X)
plt.scatter(Y, Y_pred, color='blue')
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual Prices vs. Predicted Prices')
input_values = [int(input("Enter the number of rooms: ")),
                int(input("Enter the square footage: ")),
                int(input("Enter the age: "))]
predicted_price = model.predict([input_values])
print("Predicted Price:", predicted_price[0])
plt.scatter(Y, Y_pred, color='blue', label='Actual Prices')
plt.scatter(predicted_price, predicted_price, color='red', marker='x', label='Predicted Price')
plt.legend()
plt.show()
-----------------------------------------------------------------------------------
import numpy as np
import matplotlib.pyplot as plt
data = np.array([[2, 3], [3, 4], [5, 6], [9, 10], [10, 8], [12, 12]])
k = 2
centroids = data[np.random.choice(data.shape[0], k, replace=False)]
num_iterations = 100
for iteration in range(num_iterations):
    distances = np.linalg.norm(data[:, np.newaxis] - centroids, axis=2)
    labels = np.argmin(distances, axis=1)
    print(labels)
    plt.scatter(data[:, 0], data[:, 1], c=labels)
    plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200)
    plt.xlabel("X-axis")
    plt.ylabel("Y-axis")
    plt.title(f"Iteration {iteration}")
    plt.show()
    new_centroids = np.array([data[labels == i].mean(axis=0) for i in range(k)])
    if np.array_equal(centroids, new_centroids):
        break
    centroids = new_centroids
print(distances)
print("Final Cluster Assignments:", labels)
print("Final Cluster Centroids:", centroids)
-----------------------------------------------------------------------------------
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
data = pd.read_csv('movie.csv')
X = data[['No: of Popular Celebrities', 'Estimated Budget']]
y = data['Result']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)
clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')
print(f'Confusion Matrix:\n{confusion_matrix(y_test, y_pred)}')
plt.figure(figsize=(12, 6))
plot_tree(clf, feature_names=X.columns, class_names=y.unique(), filled=True)
plt.show()
celebrities = int(input("Enter the Number of Celebrities: "))
budget = int(input("Enter the Estimated Budget: "))
input_data = pd.DataFrame({'No: of Popular Celebrities': [celebrities], 'Estimated Budget': [budget]})
prediction = clf.predict(input_data)
print("Predicted Result:", prediction[0])
-----------------------------------------------------------------------------------
import nltk
from nltk import pos_tag
from nltk.tokenize import word_tokenize
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
sentence = "Part-of-speech tagging is important for natural language processing."
words = word_tokenize(sentence)
pos_tags = pos_tag(words)
print(pos_tags)
-----------------------------------------------------------------------------------
from nltk import bigrams, trigrams, word_tokenize
sentence = "Natural language processing is fascinating."
words = word_tokenize(sentence)
unigrams_list = list(words)
print("Unigrams:", unigrams_list)
bigrams_list = list(bigrams(words))
print("Bigrams:", bigrams_list)
trigrams_list = list(trigrams(words))
print("Trigrams:", trigrams_list)
-----------------------------------------------------------------------------------
import requests
from bs4 import BeautifulSoup
def simple_web_crawler(url, max_depth=2):
    visited_urls = set()
    def crawl(url, depth):
        if depth > max_depth or url in visited_urls:
            return
        print(f"Crawling: {url}")
        try:
            response = requests.get(url)
            visited_urls.add(url)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                title = soup.title.string.strip() if soup.title else 'No title found'
                print(f"Page Title: {title}")
                for link in soup.find_all('a', href=True):
                    next_url = link['href']
                    crawl(next_url, depth + 1)
        except Exception as e:
            print(f"Error crawling {url}: {e}")
    crawl(url, depth=1)
if __name__ == "__main__":
    start_url = "https://ajce.in"
    simple_web_crawler(start_url)
-----------------------------------------------------------------------------------
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.datasets import load_iris
from tensorflow.keras import models, layers
iris = load_iris()
X = iris.data
y = iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
label_encoder = LabelEncoder()
y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)
model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(4,)))
model.add(layers.Dense(32, activation='relu'))
model.add(layers.Dense(3, activation='softmax'))
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.1)
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f'Test accuracy: {test_acc}')
-----------------------------------------------------------------------------------

